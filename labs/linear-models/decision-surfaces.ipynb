{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting decision surfaces for linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Understanding the mathematics of linear models is important, but to lock that in, it's a good idea to draw model decision surfaces for yourself.  In this lab, you will use sklearn to train linear regression and logistic regression models but extract to the model parameters and draw the surfaces and then compare to the `predict()` and `predict_proba()` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.datasets import load_wine, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston data set 1-var regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check feature importance**\n",
    "\n",
    "You'll need to do `pip install rfpimp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X, y)\n",
    "\n",
    "from rfpimp import *\n",
    "I = importances(lm, X, y)\n",
    "plot_importances(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Split off validation/test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Pick most important single var**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['LSTAT']] # pick single feature for 1-var regression\n",
    "X_test = X_test[['LSTAT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Train LinearRegression model on (X_train, y_train); use variable lm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to visualize data sets is important in machine learning. Let's display the training and test sets using a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "plt.scatter(X_train, y_train, s=15, alpha=.3)\n",
    "plt.scatter(X_test, y_test, s=15, alpha=.5, c='orange')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Create function plotting line for $(\\beta_0,\\beta_1)$ and extract betas from model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(beta, x):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "def line(beta, x):\n",
    "    return beta[0] + beta[1]*x\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "beta = np.array([lm.intercept_, lm.coef_[0]])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Plot regression line using coefficients in beta**\n",
    "\n",
    "It should look like:\n",
    "\n",
    "<img src=\"boston-linreg.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "plt.scatter(X_train, y_train, s=15, alpha=.3)\n",
    "plt.scatter(X_test, y_test, s=15, alpha=.5, c='orange')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('y')\n",
    "\n",
    "lx = np.arange(np.min(X_train['LSTAT']), np.max(X_train['LSTAT'])).reshape(-1,1)\n",
    "y_pred = ...\n",
    "plt.plot(lx, y_pred, '--',color='red', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "y_pred = line(beta,lx)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Verify that the model predictions give the same line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "plt.scatter(X_train, y_train, s=15, alpha=.3)\n",
    "plt.scatter(X_test, y_test, s=15, alpha=.5, c='orange')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('y')\n",
    "\n",
    "y_pred = ...\n",
    "plt.plot(lx, y_pred, '--',color='red', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "y_pred = lm.predict(lx)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How good is that fit? Compare your belief with $R^2$ computed on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = lm.score(...)\n",
    "print(f\"R^2 = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "r2 = lm.score(X_test, y_test)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Compare the $R^2$ computed on the test set and training set**\n",
    "\n",
    "It should be about the same because there is a clear linear relationship to exploit and the training and test sets look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = lm.score(...)\n",
    "print(f\"R^2 = {r2_train:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "r2_train = lm.score(X_train, y_train)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine data set 2-class logistic regression\n",
    "\n",
    "The wine data set has three categories or classes of wine, but we can strip out one of the categories to get a two class problem for simple logistic regression. (We'll drop class 0, but then rename classes 1,2 as 0,1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "df_wine = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "df_wine['y'] = wine.target\n",
    "df_wine = df_wine[df_wine['y']>=1] # Only do 2-class problem, classes {1,2}\n",
    "df_wine['y'] -= 1                  # rename classes as {0,1}\n",
    "X = df_wine['color_intensity']\n",
    "y = df_wine['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot12(X,y):\n",
    "    X_0 = X[y==0] # separate class 0, 1 to color differently\n",
    "    X_1 = X[y==1]\n",
    "\n",
    "    plt.figure(figsize=(4.8,1.5))\n",
    "    plt.scatter(X_0, [0]*len(X_0), s=20, alpha=.8, label='class1')\n",
    "    plt.scatter(X_1, [1]*len(X_1), s=20, alpha=.8, label='class2')\n",
    "    plt.xlabel('color_intensity')\n",
    "    plt.ylabel('class')\n",
    "    plt.legend(loc='upper left', fontsize=9)\n",
    "    plt.title(\"1D wine data set, classes 1,2\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Split off validation/test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot12(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Train and test logistic regression model**\n",
    "\n",
    "Note that `fit()` requires a matrix so you cannot pass in a one-dimensional numpy array. Use `X.values.reshape(-1,1)` to convert a vector `X` into an nx1 matrix. Also, be aware that `LogisticRegression` does regularized logistic regression by default so your model will performing better than vanilla logistic regression would do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = ...  # (Use arg solver='lbfgs' to get rid of a warning)\n",
    "lg.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "lg = LogisticRegression(solver='lbfgs')\n",
    "lg.fit(X_train.values.reshape(-1,1), y_train)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{100*lg.score(X_train.values.reshape(-1,1), y_train):.2f}% accurate on training set\")\n",
    "print(f\"{100*lg.score(X_test.values.reshape(-1,1), y_test):.2f}% accurate on test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create sigmoid function and extract betas from the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "beta = np.array([lg.intercept_[0], lg.coef_[0][0]])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Plot regression line using coefficients from model**\n",
    "\n",
    "You'll have to create the predictions manually. Recall that logistic regression predicts the probability of class 1 given a feature vector. That probability is just the sigmoid of the linear equation.  It should look like:\n",
    "\n",
    "<img src=\"wine-logreg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot12(X,y)\n",
    "\n",
    "lx = np.arange(np.min(X_train), np.max(X_train)).reshape(-1,1)\n",
    "y_pred = ...\n",
    "plt.plot(lx, y_pred, '--', c='red', lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "y_pred = sigmoid(line(beta, lx))\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Verify that the model predictions give the same line**\n",
    "\n",
    "Here we don't want classification; we want the probabilities so use function `predict_proba()` not `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot12(X,y)\n",
    "y_pred = ...\n",
    "plt.plot(lx, y_pred, '--', c='red', lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Solution</summary>\n",
    "<pre>\n",
    "y_pred = lg.predict_proba(lx)[:,1]\n",
    "</pre>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
